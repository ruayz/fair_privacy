run: # Configurations for a specific run
  random_seed: 12345 # Integer number of specifying random seed
  log_dir: exp/demo_tabular/credit/ # String for indicating where to save all the information, including models and computed signals. We can reuse the models saved in the same log_dir.
  time_log: True # Indicate whether to log the time for each step
  num_experiments: 1 # Number of total experiments

audit: # Configurations for auditing
  privacy_game: privacy_loss_model # Indicate the privacy game from privacy_loss_model
  algorithm: LOSS # String for indicating the membership inference attack. We currently support the RMIA introduced by Zarifzadeh et al. 2024(https://openreview.net/pdf?id=sT7UJh5CTc)) and the LOSS attacks
  num_ref_models: 199 # Number of reference models used to audit each target model
  device: cuda:8 # String for indicating the device we want to use for inferring signals and auditing models
  report_log: report # String that indicates the folder where we save the log and auditing report
  batch_size: 5000 # Integer number for indicating batch size for evaluating models and inferring signals.
  #data_size: 40000 # Integer number for indicating the size of the dataset in auditing. If not specified, the entire dataset is used.

train: # Configuration for training
  data_size: 100000
  model_name: LR # String for indicating the model type. We support CNN, wrn28-1, wrn28-2, wrn28-10, vgg16, mlp and speedyresnet (requires cuda). More model types can be added in model.py.
  device: cuda:8 # String for indicating the device we want to use for training models.
  batch_size: 256
  learning_rate: 0.1
  weight_decay: 0
  epochs: 50
  optimizer: SGD
   # train method
  method: dpsgd
  num_groups: 2
  epsilon: 0
  delta: 1e-5
  log_dir: runs/demo_tabular/credit/
  evaluate_angles: False
  evaluate_hessian: False
  angle_comp_step: False
  num_hutchinson_estimates: 100
  sampled_expected_loss: False

data: # Configuration for data
  dataset: credit # String indicates the name of the dataset. We support cifar10, cifar100, purchase100 and texas100 by default.
  data_dir: data/tabular
