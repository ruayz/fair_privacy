{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import sys\n",
    "from audit import exp_one_acc, exp_all_acc, exp_worst_eps, exp_estimated_epsilon, exp_all_avg_acc, exp_all_group_avg_acc\n",
    "from visual import *\n",
    "from util import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs = \"configs/raceface/raceface_regular.yaml\"\n",
    "# configs = \"configs/mnist/mnist_regular.yaml\"\n",
    "configs = \"configs/tabular/adult/adult_regular.yaml\"\n",
    "with open(configs, \"rb\") as f:\n",
    "    configs = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "dataset_name = configs[\"data\"][\"dataset\"]\n",
    "num_group = configs[\"train\"][\"num_groups\"]\n",
    "model_name = \"LR\"\n",
    "epsilon = 0\n",
    "method = \"regular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata_dir = f'{configs[\"run\"][\"log_dir\"]}{dataset_name}.pkl'\n",
    "# exp_dir = f'{configs['run']['log_dir']}{model_name}/{method}/data/data_{data_idx}/eps{epsilon}'\n",
    "exp_dir = f'{configs[\"run\"][\"log_dir\"]}{model_name}/{method}/eps{epsilon}'\n",
    "log_dir = exp_dir\n",
    "directories = {\n",
    "    \"log_dir\": log_dir,\n",
    "    \"report_dir\": f\"{log_dir}/report\",\n",
    "    \"signal_dir\": f\"{log_dir}/signals\",\n",
    "}\n",
    "\n",
    "path = subdata_dir\n",
    "if num_group == 5 or num_group == 2:\n",
    "    path = f\"data/tabular/{dataset_name}.pkl\"\n",
    "with open(path, \"rb\") as file:\n",
    "    dataset = pickle.load(file)\n",
    "\n",
    "path = directories[\"report_dir\"]\n",
    "memberships = np.load(f\"{path}/memberships.npy\")\n",
    "loss_scores = np.load(f\"{path}/loss_scores.npy\")\n",
    "\n",
    "\n",
    "all_acc = exp_all_acc(f\"{directories['report_dir']}/loss\", loss_scores, memberships, dataset, num_group)\n",
    "all_adv_acc = [[2*value-1 for value in group] for group in all_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45222"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test accuracy: 81.95\n",
      "Standard deviation: 0.0521\n"
     ]
    }
   ],
   "source": [
    "## 测试精度\n",
    "path = f\"{configs[\"train\"][\"log_dir\"]}{model_name}/{method}/eps{epsilon}\"\n",
    "with open(f\"{path}/models/models_metadata.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "test_accs = [entry[\"test_acc\"] for entry in data.values()]\n",
    "# 计算平均值和标准差\n",
    "mean_test_acc = np.mean(test_accs) * 100\n",
    "std_test_acc = np.std(test_accs)*100\n",
    "print(f\"Mean test accuracy: {mean_test_acc:.2f}\")\n",
    "print(f\"Standard deviation: {std_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5380736877523553, 0.5365177782685512]\n"
     ]
    }
   ],
   "source": [
    "group_mean = [np.mean([value for value in group]) for group in all_acc]\n",
    "print(group_mean)\n",
    "# v = (max(group_mean) - min(group_mean)) *100\n",
    "# print(f\"{v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07614737550471064, 0.07303555653710246]\n",
      "0.311\n"
     ]
    }
   ],
   "source": [
    "group_adv_mean = [np.mean([value for value in group]) for group in all_adv_acc]\n",
    "print(group_adv_mean)\n",
    "v = (max(group_adv_mean) - min(group_adv_mean)) *100\n",
    "print(f\"{v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.974\n"
     ]
    }
   ],
   "source": [
    "# worst eps\n",
    "v = exp_worst_eps(loss_scores, memberships)\n",
    "print(f\"{v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(num_group):\n",
    "#     print(max(all_acc[i]), end=' ')\n",
    "\n",
    "# group_mean = [np.mean([value for value in group]) for group in all_acc]\n",
    "# print(group_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# 可以用在跑多次pa-alooa 有多个group_adv_mean\n",
    "# \"\"\"\n",
    "# # Kruskal-Wallis 检验\n",
    "# from scipy.stats import kruskal\n",
    "\n",
    "# stat, p = kruskal(*all_adv_acc)\n",
    "# print(f\"统计量: {stat}, p值: {p}\")\n",
    "\n",
    "# # Mann-Whitney U 检验\n",
    "# from scipy.stats import mannwhitneyu\n",
    "\n",
    "# stat, p = mannwhitneyu(all_adv_acc[1], all_adv_acc[5], alternative='two-sided')\n",
    "# print(f\"统计量: {stat}, p值: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avearge mia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # configs = \"configs/raceface/raceface_regular.yaml\"\n",
    "# configs = \"configs/mnist/mnist_regular.yaml\"\n",
    "# # configs = \"configs/tabular/law/law_regular.yaml\"\n",
    "# with open(configs, \"rb\") as f:\n",
    "#     configs = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# dataset_name = configs[\"data\"][\"dataset\"]\n",
    "# num_group = configs[\"train\"][\"num_groups\"]\n",
    "# model_name = \"CNN\"\n",
    "# epsilon = 10\n",
    "# method = \"dpsgd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdata_dir = f'{configs[\"run\"][\"log_dir\"]}{dataset_name}.pkl'\n",
    "# # exp_dir = f'{configs['run']['log_dir']}{model_name}/{method}/data/data_{data_idx}/eps{epsilon}'\n",
    "# exp_dir = f'{configs[\"run\"][\"log_dir\"]}{model_name}/{method}/eps{epsilon}'\n",
    "# log_dir = exp_dir\n",
    "# directories = {\n",
    "#     \"log_dir\": log_dir,\n",
    "#     \"report_dir\": f\"{log_dir}/report\",\n",
    "#     \"signal_dir\": f\"{log_dir}/signals\",\n",
    "# }\n",
    "\n",
    "# path = subdata_dir\n",
    "# if num_group == 5 or num_group == 2:\n",
    "#     path = f\"data/tabular/{dataset_name}.pkl\"\n",
    "# with open(path, \"rb\") as file:\n",
    "#     dataset = pickle.load(file)\n",
    "\n",
    "# path = directories[\"report_dir\"]\n",
    "# memberships = np.load(f\"{path}/memberships.npy\")\n",
    "# loss_scores = np.load(f\"{path}/loss_scores.npy\")\n",
    "\n",
    "# # all_avg_acc = exp_all_avg_acc(f\"{directories['report_dir']}/loss\", loss_scores, memberships, dataset, num_group)\n",
    "# all_avg_acc = exp_all_group_avg_acc(f\"{directories['report_dir']}/loss\", loss_scores, memberships, dataset, num_group)\n",
    "# all_adv_acc = [[2*value-1 for value in group] for group in all_avg_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_mean = [np.mean([value for value in group]) for group in all_avg_acc]\n",
    "# print(group_mean)\n",
    "# # v = (max(group_mean) - min(group_mean)) *100\n",
    "# # print(f\"{v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_adv_mean = [np.mean([value for value in group]) for group in all_adv_acc]\n",
    "# print(group_adv_mean)\n",
    "# v = (max(group_adv_mean) - min(group_adv_mean)) *100\n",
    "# print(f\"{v:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy_meter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
